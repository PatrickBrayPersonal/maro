{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Tutorial to MARO Supply Chain Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/maro\")\n",
    "root_dir = os.path.abspath('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/maro'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple random policy example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple random example shows the interface of the Supply Chain Simulator and illustrates how to interact with it. As you can see in line 72 of file [*examples/supply_chain/simple_random_example.py*](https://github.com/microsoft/maro/blob/sc_tutorial/examples/supply_chain/simple_random_example.py#L72), we can deliver `ManufactureAction` and `ConsumerAction` to `Env`, and call function `step()` to trigger the simulation process. Try the simple example by:\n",
    "\n",
    "```sh\n",
    "python examples/supply_chain/simple_random_example.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-14T15:28:44.941Z"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sold': array([100., 100.]), 'demand': array([10095.,  9969.]), 'sold/demand': array([0.00990589, 0.0100311 ])}\n"
     ]
    }
   ],
   "source": [
    "!python {root_dir}/examples/supply_chain/simple_random_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction with Non-RL policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complex example leverage the RL workflow in MARO. And the example code enable many configurations. Simpler configurations are listed in file [*examples/supply_chain/rl/config.py*](https://github.com/microsoft/maro/blob/sc_tutorial/examples/supply_chain/rl/config.py). The basic ones you may need are:\n",
    "\n",
    "- `ALGO`: The algorithm to use. \"DQN\" and \"PPO\" are RL algorithms, \"EOQ\" is a rule-based algorithm, \"BSP\" is an OR-algorithm base-stock policy.\n",
    "- `TOPOLOGY`: The \"plant\" and \"super_vendor\" are toy topologies. You can use the \"SCI(_XX)\" ones if you add the topology under directory *maro/simulator/scenarios/supply_chain/topologies*\n",
    "- `PLOT_RENDER`: Render figures to show important metrics during experiment or not.\n",
    "- `EXP_NAME`: The experiment name, the experiment logs would be saved to the log path with `EXP_NAME` as the folder name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With setting `ALGO = \"EOQ\"`, we can try to simulate with the rule-based policy. Since the non-rl policy does not require any training process, we can use *evaluate_only* mode by:\n",
    "\n",
    "```sh\n",
    "python examples/rl/run_rl_example.py examples/rl/supply_chain.yml --evaluate_only\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-14T15:29:32.105Z"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/maro/maro/rl/workflows/main.py\", line 204, in <module>\n",
      "    module = importlib.import_module(os.path.basename(scenario_path))\n",
      "  File \"/usr/local/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'rl'\n"
     ]
    }
   ],
   "source": [
    "!python {root_dir}/examples/rl/run_rl_example.py {root_dir}/examples/rl/supply_chain.yml --evaluate_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction with RL policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to try trainable RL policy, you may also need to adjust the training workflow in file [*examples/rl/supply_chain.yml*](https://github.com/microsoft/maro/blob/sc_tutorial/examples/rl/supply_chain.yml). The basic ones you may need are:\n",
    "\n",
    "- `num_episodes` in line 15: Number of episode to run. Each episode is one cycle of roll-out and policy training.\n",
    "- `eval_schedule` in line 17: Intervals between two evaluation process. `eval_schedule: 5` means will evaluate every 5 episodes.\n",
    "- `interval` in line 31: Intervals between two dump action of policy network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With setting `ALGO = \"PPO\"` of *config.py*, we can try to simulate with the PPO algorithm based policy. The rl policy requires training process, so we need to enable training mode by:\n",
    "\n",
    "```sh\n",
    "python examples/rl/run_rl_example.py examples/rl/supply_chain.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!python {root_dir}/examples/rl/run_rl_example.py {root_dir}/examples/rl/supply_chain.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Much more complex configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complex solution configurations are gathered in file [*examples/supply_chain/rl/rl_component_bundle.py*](https://github.com/microsoft/maro/blob/sc_tutorial/examples/supply_chain/rl/rl_component_bundle.py), the ones you may concern about are:\n",
    "\n",
    "- `get_agent2policy` in line 67: the mapping from the entity id in the scenario to the policy alias.\n",
    "- `get_policy_creator` in line 84: what exactly the policy is for each policy alias.\n",
    "- `get_trainer_creator` in line 97: the trainer for the policy training. It is related to what algorithm to use.\n",
    "- `get_device_mapping` in line 109: the mapping from the policy alias to the training device.\n",
    "- `get_policy_trainer_mapping` in line 135: the mapping from the policy alias to the trainer alias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides, the **state shaping**, **action shaping** and **reward shaping** logics are defined in file [*examples/supply_chain/rl/env_sampler.py*](https://github.com/microsoft/maro/blob/sc_tutorial/examples/supply_chain/rl/env_sampler.py), while [*examples/supply_chain/rl/rl_agent_state.py*](https://github.com/microsoft/maro/blob/sc_tutorial/examples/supply_chain/rl/rl_agent_state.py) and [*examples/supply_chain/rl/or_agent_state.py*](https://github.com/microsoft/maro/blob/sc_tutorial/examples/supply_chain/rl/or_agent_state.py) are used by **state shaping** logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
